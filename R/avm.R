#' @title avm modeling
#'
#' @description model fitting function
#' @param data.train data for fitting generated by \code{\link{avm.data.train}} or \code{\link{data.split}}
#' @param dependentY dependent variable. The default is 'saleprice'
#' @param independentX independent variables. Using var exception,see detail.
#' @param model.list The list of model. The default is \code{list(ols=T,rlm=T,svm=T,rft=T,gwr=T,xgb=T)}
#' @param min.missing.rate The rate of missing rate for keeping, The default is 0.4 which indicting when the rate of a feature is more than 40 percent, it will be removed from data
#' @param remove.dup Logic variable indicting whether to remove duplicated coordinates.The default is T
#' @param ntree numerical value indiciting number of subtrees for random forests.The default is 1000
#' @param nround numerical value indicting iteration of xgboost.The default is 1000
#' @details parameter \code{independentX} should be written as a formula. For example, '~.-yearmonth-ymid-ha_code' means all variables except yearmonth,ymid and ha_code will be performed as features in the models.
#' @details It can also written as '~bldgrea + x + y' indicting bldgrea ,x and y will included in the sets of features . The default value is \code{paste0('~.-yearmonth-ymid-ha_code-volume_rate-greening_rate','-x_-y_-saleprice-rentprice-unitprice','-rentbldgarea-salebldgarea-bldg_type-bldg_code')}
#' @export
#' @return The list of AVM models
avm.fit<-function(data.train=NULL,
                  dependentY='saleprice',
                  independentX='~.-ha_code-saleprice',
                  model.list=list(ols=T,rlm=F,svm=F,rft=F,gwr=F,xgb=F),
                  min.missing.rate=0.4,
                  remove.dup=T,
                  ntree=500,nround=1000){
    if(is.null(data.train)){
        stop('must provide data.train!!!!')
    }
    formula.lm.saleprice<-paste(paste0('log_',dependentY),independentX)%>%as.formula
    library(formula.tools)
    data.train[,paste0('log_',dependentY)]<-log(data.train[,dependentY])
    rvars<-rhs.vars(formula.lm.saleprice,data=data.train)
    dependY.raw<-lhs.vars(formula.lm.saleprice)%>%as.character()
    # data.del.idx<-is.na(data.train[,dependentY]) | data.train[,dependentY]<=0
    # data.del<-data.train[data.del.idx,]
    # len_del<-nrow(data.del)
    # if(!is.null(data.del)&!is.null(len_del)){
    #     if(len_del>0)
    #         cat('删除为空,0和负数价格共',len_del,'条数据\n')
    # }
    idx<-data.train[,dependentY]>0
    for (i in 1:length(rvars)){
        if(mean(is.na(data.train[,rvars[i]]))>=min.missing.rate){
            cat('removed ',rvars[i],' missing rate >=',min.missing.rate,'\n')
            data.train<-data.train%>%dplyr::select(-one_of(rvars[i]))
        }
    }
    rvars<-rhs.vars(formula.lm.saleprice,data=data.train)
    formula.lm.saleprice.2<-paste(lhs.vars(formula.lm.saleprice),
                                  paste(rvars,collapse = '+'),sep='~')%>% as.formula

    data.train<-data.train[idx,]%>%dplyr::select(one_of(rvars,dependentY,dependY.raw))%>%na.omit()
    train.models<-vector(mode='list',length = length(model.list[model.list==TRUE]))
    names(train.models)<-names(model.list[model.list==TRUE])#c('ols','rlm','svm','rft','gwr','xgb')
    train.models$formula<-formula.lm.saleprice.2
    if(model.list$ols){
        cat('trainning Linear Regression','\n')
        train.models$ols<-train.ols(data.train,formula.lm.saleprice.2)
    }
    if(model.list$rlm){
        cat('trainning Robust Linear Regression','\n')
        train.models$rlm<-train.rlm(data.train,formula(train.models$ols))
    }
    if(model.list$svm){
        cat('trainning Support Vector Machine','\n')
        train.models$svm<-train.svm(data.train,formula.lm.saleprice.2)
    }
    if(model.list$rft){
        cat('trainning Random Forests','\n')
        train.models$rft<-train.rft(data.train,formula.lm.saleprice.2,ntree = ntree)
    }
    if(model.list$gwr){
        cat('trainning Geographically Weighted Regression','\n')
        train.models$gwr<-train.gwr(data.train,formula(train.models$ols),remove.dup=remove.dup)
    }
    if(model.list$xgb){
        cat('trainning eXtreme Gradient Boosting','\n')
        train.models$xgb<-train.xgb(data.train,formula.lm.saleprice.2,nround = nround)
    }
    train.models
}

train.ols<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    # rvars <- rhs.vars(formula)
    # rvars <- rvars[rvars!='bc11' & rvars!='bc12' & rvars!='bc13' & rvars!='bc21']
    # formula2 <- paste(lhs.vars(formula),paste(rvars,collapse = '+'),sep='~')%>% as.formula
    # model1 <- stats::lm(formula,data=data.train)
    # model2 <- step(stats::lm(formula2,data=data.train),trace=F)
    # if (AIC(model2)<AIC(model1)) {model1 <- model2}
    # return(model1)
    step(stats::lm(formula,data=data.train),trace=F)
}
pred.ols<-function(avm.ols=NULL,newdata=NULL){
    if(is.null(avm.ols)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    stats:::predict.lm(avm.ols,newdata=newdata)
}
train.rlm<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    MASS::rlm(formula,data=data.train)
}
pred.rlm<-function(avm.rlm=NULL,newdata=NULL){
    if(is.null(avm.rlm)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    library(MASS)
    predict(avm.rlm,newdata=newdata)
}
train.svm<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    e1071::svm(formula,data=data.train)
}
pred.svm<-function(avm.svm=NULL,newdata=NULL){
    if(is.null(avm.svm)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    e1071:::predict.svm(avm.svm,newdata = newdata)
}
train.rft<-function(data.train=NULL,formula=NULL,ntree=500){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    randomForest::randomForest(formula,data=data.train, ntree=ntree)
}
pred.rft<-function(avm.rft=NULL,newdata=NULL){
    if(is.null(avm.rft)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    randomForest:::predict.randomForest(avm.rft,newdata=newdata)
}
train.xgb<-function(data.train=NULL,formula=NULL,nround=1000){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    twidlr::xgboost(data = data.train,formula = formula,nround=nround)
}
pred.xgb<-function(avm.xgb=NULL,newdata=NULL){
    if(is.null(avm.xgb)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    depdent.y.names<-formula(avm.xgb)%>%lhs.vars()
    newdata[,depdent.y.names]<-0
    if(nrow(newdata)==1){
        newdata<-rbind(newdata,newdata)%>%data.frame()
        twidlr:::predict.xgb.Booster(object = avm.xgb,newdata)[1]
    }else{
        twidlr:::predict.xgb.Booster(object = avm.xgb,newdata)
    }

}
train.gwr<-function(data.train=NULL,formula=NULL,remove.dup=T){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    library(maptools)
    rvars<-rhs.vars(formula,data=data.train)
    rvars.withoutxy<-rvars[rvars!='x'&rvars!='y']
    formula.gwr.saleprice<-paste(lhs.vars(formula),
                                 paste(rvars.withoutxy,collapse = '+'),sep='~')%>% as.formula
    library(spgwr)
    formula.gwr.saleprice <- log_saleprice ~ hosi.poi.sp_dens + 
      trans.poi.sp_dens + busi.poi.sp_dens + poi.diversity.pts + 
      edu.poi.sp_mindist + trans.poi.sp_mindist + busi.poi.sp_mindist
    data.train <- data.train[which(!duplicated(data.train[7:8])),]
    GWRbandwidth <- gwr.sel(as.formula(formula.gwr.saleprice), data=data.train, coords=cbind(data.train$x,data.train$y),adapt=T)
    gwr.model = gwr(as.formula(formula.gwr.saleprice), 
                    data=data.train, coords=cbind(data.train$x,data.train$y), adapt=GWRbandwidth, hatmatrix=TRUE, se.fit=TRUE)
    # data.reg.sp<-sp.pts(data_ = data.train%>%na.omit(),remove.dup=remove.dup)
    # library(GWmodel)
    # DM<-gw.dist(dp.locat=coordinates(data.reg.sp),longlat = T)
    # bw1<-bw.gwr(formula.gwr.saleprice, data=data.reg.sp,dMat=DM,longlat = T,approach = 'AIC')
    # gwr.basic(formula.gwr.saleprice, data=data.reg.sp, bw=bw1,longlat = T,dMat=DM)
}
pred.gwr<-function(avm.gwr=NULL,newdata=NULL,retry=10,remove.dup=T){
    library(GWmodel)
    data.reg.sp<-avm.gwr$lm$model
    data.reg.sp$x<-coordinates(avm.gwr$SDF)[,1]
    data.reg.sp$y<-coordinates(avm.gwr$SDF)[,2]
    data.reg.sp<-sp.pts(data_ = data.reg.sp,remove.dup=remove.dup)
    # dependY.raw<-
    # lhs.vars(avm.gwr$GW.arguments$formula)%>%as.character()%>%str_replace_all('~log\\(|\\)','')
    # data.reg.sp@data[,dependY.raw]<-exp(data.reg.sp@data[,lhs.vars(avm.gwr$GW.arguments$formula)%>%
    # as.character()%>%
    # str_replace('~','')])
    if(!is(newdata,'Spatial')){
        newdata<-sp.pts(data_ = newdata,remove.dup=remove.dup)
    }
    gwr.pred<-NULL
    bw.gwr<-avm.gwr$GW.arguments$bw
    for (i in 1:retry){
        gwr.pred <- try(
            gwr.predict(avm.gwr$GW.arguments$formula,
                        data=data.reg.sp, bw=bw.gwr,
                        predictdata = newdata,longlat = T), silent=TRUE)
        if(!is(gwr.pred, 'try-error')) break
        cat('retrying with an extended bandwidth...','\n')
        bw.gwr<-bw.gwr/0.618
    }

    if(is.null(gwr.pred)){
        return(NULL)
    }else{
        return(gwr.pred$SDF$prediction)
    }
}
#' data processing for fitting
#'
#' This function is useful for generating data for fitting
#' @param tabln.vec basic data list generated by \code{\link{loadData}}
#' @param proptype type code of properties.The default values is 11 indicting housing.
#' @param bldg_code type code of building.The default is 11
#' @param var.names.except Variable names which will be exclued in the fitting. See detail
#' @details The default value of var.names.except is \code{c('city_code','proptype','year','month','salecount','rentcount','name','ha_cl_code','ha_cl_name','dist_code','dist_name')}
#' @export
#' @return trainning data for AVM
avm.data.train<-function(tabln.vec=NULL,
                         proptype='11',modelpath1=NULL, city_code=NULL,
                         var.names.except=
                           c('name','ha_cl_code','buildyear','volume_rate','greening_rate',"proptype",
                             'ha_cl_name','dist_code','dist_name','x_',"y_","bldg_code","year","month")){
  ppi_sale<-ppsale(tabln.vec = tabln.vec,proptype = proptype,modelpath1,city_code)
  # ppi_sale$yearmonth<-paste(ppi_sale$year,ppi_sale$month,sep = '-')
  data.train<-ppi_sale%>%dplyr::select(-one_of(var.names.except))
  # data.train[data.train=='NA-NA'] <- NA
  return(data.train)
}

#' @title data spliting
#'
#' @description This function is useful for spliting training and testing data
#' @param data all data sets provided by \code{\link{avm.data.train}}
#' @param train.rate the rate for training. Default value is 0.7, which means 70\% of data will be used in the fitting
#' @export
#' @return a list contain train and test data
data.split<-function(data,train.rate=0.7){
    library(magrittr)
    idx.train<-sample(1:nrow(data),size = nrow(data)*train.rate)%>%sort()
    data.train<-data[idx.train,]
    data.test<-data[-idx.train,]
    list(train=data.train,test=data.test)
}

#' avm prediction function
#'
#' This function will predict according given data
#' @param train.models obejct of models provided by \code{\link{avm.fit}}
#' @param model.list The list of model .The default is \code{list(ols=T,rlm=T,svm=T,rft=T,gwr=T,xgb=T)}
#' @param newdata Testing data or unkown data for prediction. Tesing data is provided by \code{\link{data.split}}
#' @param testing Logic value indicting whether to test.The default is F
#' @param remove.dup Logic variable indicting whether to remove duplicated coordinates.The default is T
#' @export
#' @return prediction value . It will contain rmse and mae for testing if testing is T
avm.pred<-function(train.models=NULL,
                   model.list=list(ols=T,rlm=T,svm=T,rft=T,gwr=T,xgb=T),
                   newdata=NULL,
                   testing=F,remove.dup=T
                   ){
    if(is.null(train.models)|is.null(newdata)){
        stop('models or newdata can not be NULL!!!!')
    }
    if(testing){
        dependent.name<-(train.models$ols%>%model.frame()%>%colnames())[1]
        dependY.raw<-dependent.name%>%stringr::str_replace_all('log_','')
        sb.idx<-newdata[,dependY.raw]<=0
        actual<-log(newdata[,dependY.raw]+1e-6)
        model.rmse<-vector(mode='list',length = length(model.list) )
        names(model.rmse)<-names(model.list)#c('ols','rlm','svm','rft','gwr','gwr2','xgb')
        model.mae<-model.rmse
        res<-data.frame(y=actual)
    }else{
        res<-data.frame(x=newdata$x,y=newdata$y)
    }
    rvars<-train.models$formula%>%rhs.vars(data=newdata)
    if(is(newdata,'Spatial')){
        newdata@data<-dplyr::select(newdata@data,one_of(rvars))
    }else{
        newdata<-dplyr::select(newdata,one_of(rvars))
    }

    if(model.list$ols){
        cat('predicting Linear Regression','\n')
        res$ols.pred<-pred.ols(train.models$ols,newdata = newdata)
        if(testing){
            error<-actual-res$ols.pred
            model.rmse$ols<-rmse(error,sb.idx)
            model.mae$ols<-mae(error,sb.idx)
        }
    }
    if(model.list$rlm){
        cat('predicting Robust Linear Regression','\n')
        res$rlm.pred<-pred.rlm(train.models$rlm,newdata = newdata)
        if(testing){
            error<-actual-res$rlm.pred
            model.rmse$rlm<-rmse(error,sb.idx)
            model.mae$rlm<-mae(error,sb.idx)
        }
    }
    if(model.list$svm){
        cat('predicting Support Vector Machine','\n')
        res$svm.pred<-pred.svm(train.models$svm,newdata = newdata)
        if(testing){
            error<-actual-res$svm.pred
            model.rmse$svm<-rmse(error,sb.idx)
            model.mae$svm<-mae(error,sb.idx)
        }
    }
    if(model.list$rft){
        cat('predicting Random Forests','\n')
        res$rft.pred<-pred.rft(train.models$rft,newdata = newdata)
        if(testing){
            error<-actual-res$rft.pred
            model.rmse$rft<-rmse(error,sb.idx)
            model.mae$rft<-mae(error,sb.idx)
        }
    }
    if(model.list$gwr){
        cat('predicting Geographically Weighted Regression','\n')
        res$gwr.pred<-pred.gwr(train.models$gwr,newdata = newdata,remove.dup=remove.dup)
        if(testing){
            error<-actual-res$gwr.pred
            model.rmse$gwr<-rmse(error,sb.idx)
            model.mae$gwr<-mae(error,sb.idx)
        }
    }
    if(model.list$xgb){
        cat('predicting eXtreme Gradient Boosting','\n')
        res$xgb.pred<-pred.xgb(train.models$xgb,newdata = newdata)
        if(testing){
            error<-actual-res$xgb.pred
            model.rmse$xgb<-rmse(error,sb.idx)
            model.mae$xgb<-mae(error,sb.idx)
        }
    }
    if(testing){
        model.res<-list(res,model.rmse%>%unlist(),model.mae%>%unlist())
        names(model.res)<-c('pred','rmse','mae')
    }else{
        model.res<-res
    }
    model.res
}

#' generate data for prediction
#'
#' This function will generate data for given data
#' @param train.models object of models provided by \code{\link{avm.fit}},required pameter.
#' @param proptype type code of properties.The default is 11 which means housing.
#' @param bldg_code tyep code of building.The default is 11
#' @param bldg_area area of building . The default value is 80
#' @param br number beedroom. The default is 2
#' @param buildyear year of building. The default is current year.
#' @param x lon,required
#' @param y lat,required
#' @param tabln.vec basic data provided by \code{\link{loadData}}
#' @param poi.data.list data of POI ,required . It will be provided by \code{\link{getpoi.ras}}
#' @param spatial logic parameter indicintg whether to return spatial variables. The default is F
#' @import stringr
#' @export
#' @return data used for predictiong
avm.pred.data<-function(train.models=NULL,
                        proptype='11',
                        # bldg_code='11',
                        # bldg_area=80,
                        # br=2,
                        # buildyear=as.numeric(format(Sys.Date(),'%Y')),
                        x=NULL,
                        y=NULL,
                        tabln.vec=NULL,
                        poi.data.list=NULL,
                        spatial=F){
    if(is.null(x)|is.null(y)|is.null(poi.data.list)|is.null(train.models)){
        stop( "coordinates,poidata or train.models can't be NULL")
    }
    formula.pred<-train.models$formula
    library(formula.tools)
    rvars<-rhs.vars(formula.pred,data=train.models$ols$model)
    pred.xy<-data.frame(x=x,y=y)
    pred.xy<-sp.pts(pred.xy)
    poi.dens.pts<-sapply(poi.data.list$poi.dens,extract,y=pred.xy,sp=F)
    if(nrow(pred.xy)<=1){
        poi.dens.pts<-data.frame(t(poi.dens.pts))
    }
    colnames(poi.dens.pts)<-paste0(colnames(poi.dens.pts),'_dens')
    poi.diversity.pts<-extract(x = poi.data.list$poi.diversity,y=pred.xy,sp=F)

    # extract all poi spatial dataframe
    which.poi.sp<-stringr::str_detect(names(tabln.vec),pattern = '\\.poi\\.sp')
    poi.sp.names<-names(tabln.vec)[which.poi.sp]

    poi.mindist<-sapply(X = poi.sp.names, getMindist,ha=pred.xy,list=tabln.vec)
    if(nrow(pred.xy)<=1){
        poi.mindist<-data.frame(t(poi.mindist))
    }
    colnames(poi.mindist)<-paste0(colnames(poi.mindist),'_mindist')
    pred.xy@data<-cbind(pred.xy@data,
                           poi.dens.pts,
                           poi.diversity.pts,
                           poi.mindist)%>%as.data.frame
    for(i in 1:length(rvars)){
        if(!rvars[i] %in% names(pred.xy)){
            pred.xy@data[,rvars[i]]<-0
            if(stringr::str_detect(rvars[i],'year')){
                pred.xy@data[,rvars[i]]<-buildyear
            }
            if(stringr::str_detect(rvars[i],'area')){
                pred.xy@data[,rvars[i]]<-bldg_area
            }
            if(rvars[i]=='br'){
                pred.xy@data[,rvars[i]]<-br
            }
        }
    }
    # pred.xy$proptype<-proptype
    # pred.xy$bldg_code<-bldg_code
    # pred.xy$buildyear<-buildyear
    if(!spatial){
        pred.xy<-pred.xy@data
    }
    pred.xy
}
# Function that returns Root Mean Squared Error
rmse <- function(error,idx.sb=NULL)
{
    if(!is.null(idx.sb)){
        error[idx.sb]<-NA
    }
    sqrt(mean(error^2,na.rm=T))
}

# Function that returns Mean Absolute Error
mae <- function(error,idx.sb=NULL)
{
    if(!is.null(idx.sb)){
        error[idx.sb]<-NA
    }
    mean(abs(error),na.rm=T)
}

#' This function is used for predicating in all spatial area
#' @param train.models avmmodels made before
#' @param tabln.vec containing community basal information
#' @param poi.data.list containg poi information
#' @param model.list select your models
#' @param data.sets.all all valuable data
#' @export
#' @return trainning data for AVM
avm.predall<-function(train.models,tabln.vec,poi.data.list,data.sets.all,model.list,bldg_code,remove.dup=T){
  spmin <- log(min(data.sets.all$saleprice)*0.9)
  spmax <- log(max(data.sets.all$saleprice)*1.1)

  if(is.null(train.models)){
    stop('models can not be NULL!!!!')
  }

  newdata <- tabln.vec$ha_info.sp
  # df <- merge(newdata,dplyr::select(data.sets.all,c("ha_code","bc11","bc12","bc13","bc21")),by="ha_code",all.x=TRUE) %>% as.data.frame()
  # df$bc11 <- ifelse(is.na(df$bc11.y),df$bc11.x,df$bc11.y)
  # df$bc12 <- ifelse(is.na(df$bc12.y),df$bc12.x,df$bc12.y)
  # df$bc13 <- ifelse(is.na(df$bc13.y),df$bc13.x,df$bc13.y)
  # df$bc21 <- ifelse(is.na(df$bc21.y),df$bc21.x,df$bc21.y)
  
  newdata@data$bc11 <- 0
  newdata@data$bc12 <- 0
  newdata@data$bc13 <- 0
  newdata@data$bc21 <- 0
  
  newdata@data[,which(names(newdata)==paste0('bc',bldg_code))] <- 1

  newdata <- subset(newdata,select=-c(name,ha_cl_name,ha_cl_code,dist_code,dist_name,
                                      volume_rate,greening_rate)) %>% na.omit()
  
  res<-data.frame(x=newdata$x,y=newdata$y)

  # x variable names
  rvars<-train.models$formula%>%rhs.vars(data=newdata)
  
  if(is(newdata,'Spatial')){
    newdata@data<-dplyr::select(newdata@data,one_of(rvars))
  }else{
    newdata<-dplyr::select(newdata,one_of(rvars))
  }

  if(model.list$ols){
    cat('predicting Linear Regression','\n')
    res$ols.pred<-pred.ols(train.models$ols,newdata = newdata@data)
  }
  if(model.list$rlm){
    cat('predicting Robust Linear Regression','\n')
    res$rlm.pred<-pred.rlm(train.models$rlm,newdata = newdata@data)
  }
  if(model.list$svm){
    cat('predicting Support Vector Machine','\n')
    res$svm.pred<-pred.svm(train.models$svm,newdata = newdata@data)
  }
  if(model.list$rft){
    cat('predicting Random Forests','\n')
    res$rft.pred<-pred.rft(train.models$rft,newdata = newdata@data)
  }
  if(model.list$gwr){
    cat('predicting Geographically Weighted Regression','\n')
    res$gwr.pred<-pred.gwr(train.models$gwr,newdata = newdata,remove.dup=remove.dup)
  }
  if(model.list$xgb){
    cat('predicting eXtreme Gradient Boosting','\n')
    res$xgb.pred<-pred.xgb(train.models$xgb,newdata = newdata@data)
  }

  crs3857 <- "+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs"
  resxy <- project(as.matrix(res[1:2]),proj=crs3857)  # class: matrix
  respred <- subset(res,select=-c(x,y))

  resraster <- rasterize(resxy,raster(poi.data.list$poi.dens$edu.poi.sp),field=respred)

  # control the max/in saleprice between (spmin,spmax)
  resraster[resraster>spmax] <- spmax
  resraster[resraster<spmin] <- spmin

  return(resraster)
}


#' This function is used for choosing the best model by the indicator of RMSE
#' @param models avmmodels made before
#' @param testdata test data from data.sets, data.sets$test
#' @param model.list models
#' @export
#' @return the best model
select_model <- function(models,testdata,model.list){
  # actual saleprice, convert to log
  actuals <- log(testdata$saleprice)
  # how many models? (-1), delete the formula dim
  nmodels <- length(models)-1
  # x variable names
  rvars <- models$formula%>%rhs.vars(data=testdata)
  # 
  testdata <- dplyr::select(testdata,one_of(rvars))
  # convert the testdata to dataframe
  preds<-data.frame("ols.pred"=rep(NA,nrow(testdata)),"rlm.pred"=rep(NA,nrow(testdata)),
                    "svm.pred"=rep(NA,nrow(testdata)),"rft.pred"=rep(NA,nrow(testdata)),
                    "gwr.pred"=rep(NA,nrow(testdata)),"xgb.pred"=rep(NA,nrow(testdata)))

  if (model.list$ols) preds$ols.pred <- pred.ols(models$ols,testdata)
  if (model.list$rlm) preds$rlm.pred <- pred.rlm(models$rlm,testdata)
  if (model.list$svm) preds$svm.pred <- pred.svm(models$svm,testdata)
  if (model.list$rft) preds$rft.pred <- pred.rft(models$rft,testdata)
  if (model.list$gwr) preds$gwr.pred <- pred.gwr(models$gwr,testdata)
  if (model.list$xgb) preds$xgb.pred <- pred.xgb(models$xgb,testdata)
  
  preds <- dplyr::select(preds,paste0(names(model.list[model.list==TRUE]),".pred"))
  
  # calculate the errors
  errors <- preds-actuals
  rmses <- sapply(errors, rmse)
  
  bestmodel <- substr(names(which(rmses==min(rmses))),1,3)
  cat("The best model is",bestmodel)
  return(bestmodel)
  #
}
